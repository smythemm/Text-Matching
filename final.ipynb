{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import datrie\r\n",
    "import string\r\n",
    "import sklearn.cluster\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import warnings\r\n",
    "\r\n",
    "from numba import jit\r\n",
    "from numba.typed import Dict\r\n",
    "from numba import types\r\n",
    "from openpyxl import Workbook\r\n",
    "\r\n",
    "from myLevenshtein import Levenshtein_modified\r\n",
    "from Get_Similar_Words import find_suggestion\r\n",
    "\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.1 Tag Name / Value to Tag Master Name / Value Mapping ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Load all dataset\n",
    "- Simple data pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "raw_data = []\r\n",
    "for dirpath, dirnames, filenames in os.walk('data/Azure'):\r\n",
    "    for filename in filenames:\r\n",
    "        df = pd.read_csv(dirpath + '/' + filename, low_memory=False, header=1)\r\n",
    "        df = df[['Date', 'AccountId', 'AccountName', 'DepartmentId', 'DepartmentName', 'InstanceId', 'ResourceGroup', 'Tags']]\r\n",
    "        df['ResourceName'] = df['InstanceId'].str.split('/').apply(lambda x: x[-1])\r\n",
    "        raw_data.append(df.drop(columns=['InstanceId']))\r\n",
    "raw_data = pd.concat(raw_data)\r\n",
    "data = raw_data.dropna(subset=['Tags', 'ResourceGroup']).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Parse Tags using `numba` to speed up, time-consuming < 4s, which takes around 30s without `numba`\n",
    "- Filter Tag which has no Tag Value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "numba_dict = Dict.empty(key_type=types.int64, value_type=types.UniTuple(types.string, 2))\r\n",
    "\r\n",
    "\r\n",
    "@jit(nopython=True, nogil=True, parallel=True)\r\n",
    "def get_all_tags_typed_dict(all_tags_list, numba_dict):\r\n",
    "    index = np.int64(0)\r\n",
    "    for tags in all_tags_list:\r\n",
    "        tags = tags.replace('\"', '')\r\n",
    "        tags = tags[3:-1].split(',  ')\r\n",
    "        for tag in tags:\r\n",
    "            tmp = tag.split(': ')\r\n",
    "            if tmp[1] != '':\r\n",
    "                numba_dict[index] = (tmp[0], tmp[1])\r\n",
    "                index += 1\r\n",
    "\r\n",
    "    return numba_dict\r\n",
    "\r\n",
    "\r\n",
    "all_tags_typed_dict = get_all_tags_typed_dict(data['Tags'].tolist(), numba_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Transfer to pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "all_tags_df = pd.DataFrame.from_dict(all_tags_typed_dict, orient='index', columns=['Tag Name', 'Tag Value'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Define method to get Tag Master Names / Tag Master Values  \n",
    "*Hint:* Use `Affinity Propagation (AP)` to choose Master Names / Values automatically, this method doesn't need to identify the number of clusters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_master(words, **kwargs):\r\n",
    "    damping = kwargs.get('damping', 0.5)\r\n",
    "    max_iter = kwargs.get('max_iter', 200)\r\n",
    "    convergence_iter = kwargs.get('convergence_iter', 15)\r\n",
    "    similarity = kwargs.get('similarity', None)\r\n",
    "    affinity = 'euclidean' if similarity is None else 'precomputed'\r\n",
    "    preference = kwargs.get('preference', None)\r\n",
    "\r\n",
    "    if affinity == 'euclidean':\r\n",
    "        ap = sklearn.cluster.AffinityPropagation(affinity=affinity,\r\n",
    "                                                 damping=damping,\r\n",
    "                                                 max_iter=max_iter,\r\n",
    "                                                 convergence_iter=convergence_iter).fit(words)\r\n",
    "    else:\r\n",
    "        preference = np.median(similarity) if preference is None else preference\r\n",
    "        ap = sklearn.cluster.AffinityPropagation(affinity=affinity,\r\n",
    "                                                 damping=damping,\r\n",
    "                                                 preference=preference,\r\n",
    "                                                 max_iter=max_iter,\r\n",
    "                                                 convergence_iter=convergence_iter).fit(similarity)\r\n",
    "\r\n",
    "    master = {}\r\n",
    "    index = 0\r\n",
    "    for cluster_id in np.unique(ap.labels_):\r\n",
    "        exemplar = words[ap.cluster_centers_indices_[cluster_id]]\r\n",
    "        cluster = np.unique(words[np.nonzero(ap.labels_ == cluster_id)])\r\n",
    "        cluster_str = ', '.join(cluster)\r\n",
    "        print(\" - *%s:* %s\" % (exemplar, cluster_str))\r\n",
    "        for point in cluster:\r\n",
    "            master[index] = {'0': point, '1': exemplar}\r\n",
    "            index += 1\r\n",
    "    return master"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Get Tag Master Names\n",
    "- Store result in csv to quickly call and check them conveniently later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tag_names = all_tags_df.groupby('Tag Name')['Tag Value'].count().to_dict()\r\n",
    "words = np.asarray(list(tag_names.keys()))\r\n",
    "similarity = [[-Levenshtein_modified(w1, w2, True) for w2 in words] for w1 in words]\r\n",
    "tmp = list(tag_names.values())\r\n",
    "tmp_sum = np.sum(tmp)\r\n",
    "preference = [-(1 - i / tmp_sum)*3 for i in tmp]\r\n",
    "\r\n",
    "master_names_dict = get_master(words, similarity=similarity, preference=preference)\r\n",
    "master_names_df = pd.DataFrame.from_dict(master_names_dict, orient='index')\r\n",
    "master_names_df.columns = ['Tag Name', 'Tag Master Name']\r\n",
    "master_names_df.to_csv('./result/Tag Master Names.csv', sep=',', header=True, index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - *Client:* Client, client, x_Client\n",
      " - *ClusterId:* ClusterId\n",
      " - *ClusterName:* ClusterName\n",
      " - *Creator:* Creator, DatabricksInstancePoolCreatorId, x_Creator\n",
      " - *DataFactoryEntityResourceId:* DataFactoryEntityResourceId\n",
      " - *Databricks-ElasticDisk:* Databricks-ElasticDisk\n",
      " - *DatabricksInstanceGroupId:* DatabricksInstanceGroupId\n",
      " - *DatabricksInstancePoolId:* DatabricksInstancePoolId\n",
      " - *Environment:* DatabricksEnvironment, Enviornment, Environment, databricks-environment, environment\n",
      " - *JobId:* JobId\n",
      " - *MappingDataflowRunId:* MappingDataflowRunId\n",
      " - *Product:* Product\n",
      " - *ResourceClass:* ResourceClass\n",
      " - *RunName:* RunName\n",
      " - *Service:* Service, x_Service\n",
      " - *SqlEndpointId:* SqlEndpointId\n",
      " - *Type:* Type, type, x_Type\n",
      " - *Vendor:* Vendor\n",
      " - *application:* application\n",
      " - *createdBy:* createdBy\n",
      " - *databricks-instance-name:* databricks-instance-name\n",
      " - *dbsql-channel:* dbsql-channel\n",
      " - *hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/components/waweprodom:* hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/components/waweprodom\n",
      " - *hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/webtests/om-avail-waweprodom:* hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/webtests/om-avail-waweprodom\n",
      " - *ms-resource-usage:* ms-resource-usage\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Get Tag Master Values for some Tag Master Names, which can be changed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "master_names = ['Client', 'Type']\r\n",
    "master_values_df = []\r\n",
    "for master_name in master_names:\r\n",
    "    tag_values = all_tags_df[all_tags_df['Tag Name'].str.contains('|'.join(master_names_df[master_names_df['Tag Master Name'] == master_name]['Tag Name']))]\r\n",
    "    tag_values = tag_values.groupby('Tag Value')['Tag Name'].count()\r\n",
    "    tag_values = tag_values[tag_values>5].to_dict()\r\n",
    "\r\n",
    "    words = np.asarray(list(tag_values.keys()))\r\n",
    "    similarity = [[-Levenshtein_modified(w1, w2, True) for w2 in words] for w1 in words]\r\n",
    "    tmp = list(tag_values.values())\r\n",
    "    tmp_sum = np.sum(tmp)\r\n",
    "    preference = [-(1 - i / tmp_sum) for i in tmp]\r\n",
    "\r\n",
    "    master_values_dict = get_master(words, similarity=similarity, preference=preference)\r\n",
    "    tmp = pd.DataFrame.from_dict(master_values_dict, orient='index')\r\n",
    "    tmp.columns = ['Tag Value', 'Tag Master Value']\r\n",
    "    tmp['Tag Master Name'] = [master_name] * len(tmp)\r\n",
    "    master_values_df.append(tmp)\r\n",
    "\r\n",
    "master_values_df = pd.concat(master_values_df, ignore_index=True)\r\n",
    "master_values_df.to_csv('./result/Tag Master Values.csv', sep=',', header=True, index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - *ARM:* ARM\n",
      " - *Absa:* ABSA, ABSACF, ABSACLOUD313, ABSACLOUDQA, ABSARBB, Absa\n",
      " - *Alexander Forbes:* Alexander Forbes\n",
      " - *Blue Label Telecoms:* Blue Label Telecoms\n",
      " - *CCBA:* CCBA, CCBACloud, ccba\n",
      " - *Carlisle:* Carlisle\n",
      " - *Discovery:* Discovery\n",
      " - *Edcon:* Edcon\n",
      " - *Ellix:* Ellix\n",
      " - *Exxaro:* Exxaro\n",
      " - *HCC:* HC, HCC\n",
      " - *Internal:* Internal, Internal - Cloud, Internal - Multi-Dim, Internal - Scenarios\n",
      " - *Internal - Pentest:* Internal - Pentest, Pentest\n",
      " - *Investec:* Investec\n",
      " - *KMOD:* KMOD\n",
      " - *Liberty:* Liberty\n",
      " - *Massmart:* Massmart\n",
      " - *NTT:* NTT\n",
      " - *National Life:* National Life\n",
      " - *OECD:* OECD, oecd\n",
      " - *Old Mutual:* OLD MUTUAL, Old Mutual, OldMutual\n",
      " - *QAmultidim:* QA multidim hybrid, QAmultidim, qa multidim hybrid, qamultidim\n",
      " - *RMB:* RMB\n",
      " - *SANDBOX:* SANDBOX\n",
      " - *SPAR:* SPAR, SPARCLOUD, Spar, sparcloud\n",
      " - *Sanlam:* Sanlam\n",
      " - *Shared:* Shared, Shared Services\n",
      " - *Stanlib:* STANLIB, Stanlib, stanlib\n",
      " - *Suncorp:* Suncorp\n",
      " - *TFG:* TFG\n",
      " - *Vitality:* Vitality\n",
      " - *pb3Test:* pb3Test, pb3test\n",
      " - *qa bnf:* qa bnf, qabnf\n",
      " - *qa cloud:* qa cloud, qacloud\n",
      " - *qa313:* QA313, qa313\n",
      " - *qa314:* QA314, qa314\n",
      " - *qaauto:* qaauto\n",
      " - *Dedicated:* Dedicated\n",
      " - *Shared:* Shared\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Match Tag Name to Tag Master Name & give matching percentage\n",
    "- Store Tag Master Value in Trie to quickly find whether one string exsits, whose time complexity is *O(n)*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "words = np.asarray(list(tag_names.keys()))\r\n",
    "\r\n",
    "\r\n",
    "def lev_metric(x, y):\r\n",
    "    i, j = int(x[0]), int(y[0])  # extract indices\r\n",
    "    return Levenshtein_modified(words[i], words[j])\r\n",
    "\r\n",
    "\r\n",
    "x = np.arange(len(words)).reshape(-1, 1)\r\n",
    "db = sklearn.cluster.DBSCAN(metric=lev_metric, eps=2, min_samples=1).fit(x)\r\n",
    "for cluster_id in np.unique(db.labels_):\r\n",
    "    cluster = words[np.nonzero(db.labels_ == cluster_id)]\r\n",
    "    cluster_str = ', '.join(cluster)\r\n",
    "    print(' -', cluster_str)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - Client, client, x_Client\n",
      " - ClusterId\n",
      " - ClusterName\n",
      " - Creator, x_Creator\n",
      " - DataFactoryEntityResourceId\n",
      " - Databricks-ElasticDisk\n",
      " - DatabricksEnvironment, databricks-environment\n",
      " - DatabricksInstanceGroupId\n",
      " - DatabricksInstancePoolCreatorId\n",
      " - DatabricksInstancePoolId\n",
      " - Enviornment, Environment, environment\n",
      " - JobId\n",
      " - MappingDataflowRunId\n",
      " - Product\n",
      " - ResourceClass\n",
      " - RunName\n",
      " - Service, x_Service\n",
      " - SqlEndpointId\n",
      " - Type, type, x_Type\n",
      " - Vendor\n",
      " - application\n",
      " - createdBy\n",
      " - databricks-instance-name\n",
      " - dbsql-channel\n",
      " - hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/components/waweprodom\n",
      " - hidden-link:/subscriptions/f6650bec-0252-45ce-b7ce-8fff251c4dad/resourcegroups/OldMutual/providers/microsoft.insights/webtests/om-avail-waweprodom\n",
      " - ms-resource-usage\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "trie1 = datrie.Trie(string.ascii_lowercase + string.digits)\r\n",
    "master_names_df = pd.read_csv('./result/Tag Master Names.csv', low_memory=False)\r\n",
    "master_names = master_names_df['Tag Master Name'].unique()\r\n",
    "for i in range(len(master_names)):\r\n",
    "    trie1[''.join(filter(str.isalnum, str(master_names[i]).lower()))] = i\r\n",
    "trie1.save('./result/Tag Master Name Trie.txt')\r\n",
    "\r\n",
    "trie2 = datrie.Trie(string.ascii_lowercase + string.digits)\r\n",
    "master_values_df = pd.read_csv('./result/Tag Master Values.csv', low_memory=False)\r\n",
    "master_values = master_values_df['Tag Master Value'].unique()\r\n",
    "for i in range(len(master_values)):\r\n",
    "    trie2[''.join(filter(str.isalnum, str(master_values[i]).lower()))] = i\r\n",
    "trie2.save('./result/Tag Master Value Trie.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "trie = datrie.Trie.load('./result/Tag Master Name Trie.txt')\r\n",
    "tag = 'DatabrickInstace'\r\n",
    "tag = ''.join(filter(str.isalnum, tag.lower()))\r\n",
    "test_list = [tag[i:i + 4] for i in range(len(tag))]\r\n",
    "\r\n",
    "suggestion = []\r\n",
    "for t in test_list:\r\n",
    "    res = trie.items(t)\r\n",
    "    for r in res:\r\n",
    "        master = master_names[r[1]]\r\n",
    "        distance = Levenshtein_modified(tag, master)\r\n",
    "        percentage = (1 - distance / max(len(master), len(tag))) * 100\r\n",
    "        if distance != 1000:\r\n",
    "            suggestion.append([master, distance, f'{percentage:.2f}%'])\r\n",
    "suggestion = np.array(suggestion)\r\n",
    "suggestion = suggestion[np.argsort(suggestion[:, 2])][::-1]\r\n",
    "suggestion"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['databricks-instance-name', '6.0', '75.00%'],\n",
       "       ['DatabricksInstancePoolId', '8.0', '66.67%'],\n",
       "       ['DatabricksInstanceGroupId', '9.0', '64.00%']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "trie = datrie.Trie.load('./result/Tag Master Value Trie.txt')\r\n",
    "tag = 'waweabsacfadmin'\r\n",
    "tag = ''.join(filter(str.isalnum, tag.lower()))\r\n",
    "test_list = [tag[i:i + 4] for i in range(len(tag))]\r\n",
    "\r\n",
    "suggestion = []\r\n",
    "for t in test_list:\r\n",
    "    res = trie.items(t)\r\n",
    "    for r in res:\r\n",
    "        master = master_values[r[1]]\r\n",
    "        distance = Levenshtein_modified(tag, master)\r\n",
    "        percentage = (1 - distance / max(len(master), len(tag))) * 100\r\n",
    "        if distance != 1000:\r\n",
    "            suggestion.append([master, distance, f'{percentage:.2f}%'])\r\n",
    "suggestion = np.array(suggestion)\r\n",
    "suggestion = suggestion[np.argsort(suggestion[:, 2])][::-1]\r\n",
    "suggestion"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['Absa', '11.0', '26.67%']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.2 MO Code & CC Code Matching ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Load dataset\n",
    "- Parse \"cloud_tags\" to extract \"resourcetags_user_costcenter\" & \"resourcetags_user_appid\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# AWS raw data is too large and we only need the column of 'cloud_tags'\r\n",
    "data_aws = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='Tags Extracted')\r\n",
    "data_aws = data_aws.dropna().reset_index()\r\n",
    "\r\n",
    "data_aws_mo = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='measured object hierarchy - 202')\r\n",
    "data_aws_mo = data_aws_mo.dropna(subset=['MeasuredObjectCode']).reset_index()\r\n",
    "\r\n",
    "data_aws_cc = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='cost centre hierarchy - 2022062')\r\n",
    "data_aws_cc = data_aws_cc.dropna(subset=['CostCentreCode']).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_costcenter_appid(all_tags_list):\r\n",
    "    costercenter, appid = [], []\r\n",
    "    for tags in all_tags_list:\r\n",
    "        tags = (tags.replace('\"', '')).replace('\\\\', '')\r\n",
    "        tags = tags[1:-1].split(', ')\r\n",
    "        for tag in tags:\r\n",
    "            tmp = tag.split(' : ')\r\n",
    "            if tmp[0] == 'resourcetags_user_costcenter':\r\n",
    "                costercenter.append(tmp[1])\r\n",
    "            if tmp[0] == 'resourcetags_user_appid':\r\n",
    "                appid.append(tmp[1])\r\n",
    "\r\n",
    "    return costercenter, appid\r\n",
    "\r\n",
    "costercenter, appid = get_costcenter_appid(data_aws['cloud_tags'].to_list())\r\n",
    "costercenter, appid = np.unique(costercenter), np.unique(appid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Store Measured Object Code & Cost Centre Code in Trie"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "mo = data_aws_mo['MeasuredObjectCode'].astype(str).unique()\r\n",
    "cc = data_aws_cc['CostCentreCode'].astype(str).unique()\r\n",
    "\r\n",
    "# 10: MeasuredObjectCode\r\n",
    "# 01: CostCentreCode\r\n",
    "# 11: is both MeasuredObjectCode and CostCentreCode\r\n",
    "trie = datrie.Trie(string.ascii_letters + string.digits + ' .-_')\r\n",
    "for m in mo:\r\n",
    "    trie[m] = 10\r\n",
    "for c in cc:\r\n",
    "    trie[c] = 11 if c in trie else 1\r\n",
    "trie.save('./result/MO_CC Code Trie.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Check each 'resourcetags_user_costcenter' & 'resourcetags_user_appid' value\n",
    "- Store results in xlsx"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def mo_cc_match(test_values, test_name, writer, sheet_name):\r\n",
    "    res = {}\r\n",
    "    index = 0\r\n",
    "    for c in test_values:\r\n",
    "        tmp = trie[str(c)] if str(c) in trie else 0\r\n",
    "        match1 = c if tmp // 10 else 'No'\r\n",
    "        match2 = c if tmp % 10 else 'No'\r\n",
    "        res[index] = (c, match1, match2)\r\n",
    "        index += 1\r\n",
    "    res = pd.DataFrame(res).T\r\n",
    "    res.columns = [test_name, 'MO Code Match', 'CC Code Match']\r\n",
    "    res.to_excel(writer, sheet_name=sheet_name, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "file_name = './result/MO_CC Code Match.xlsx'\r\n",
    "if not os.path.exists(file_name):\r\n",
    "    Workbook().save(file_name)\r\n",
    "writer = pd.ExcelWriter(file_name, engine='openpyxl', mode='w')\r\n",
    "mo_cc_match(costercenter, 'resourcetags_user_costcenter', writer, 'user_costcenter')\r\n",
    "mo_cc_match(appid, 'resourcetags_user_appid', writer, 'user_appid')\r\n",
    "writer.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- If need, can find suggestions given a number of suggestions, here just a example\r\n",
    "- To save time, store MO/CC Code in Trie in advance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "test_code = 'MO_APP4512'\r\n",
    "trie = datrie.Trie.load('./result/MO_CC Code Trie.txt')\r\n",
    "find_suggestion(trie, test_code, 4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['MO_APP4510', 'MO_APP4511', 'MO_APP4512', 'MO_APP4513']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.3 Unique Tag Value Check ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "data_unique = pd.read_excel('./data/3.3 MagicOrange Unique Tag Value Use Case Sample Set.xlsx', sheet_name='3.3 Unstructured Results')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Delete rows where all both 'ResourceGroup' and 'Resource' are missing\n",
    "- Filter duplicated data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "data_unique.dropna(how='all', inplace=True)\r\n",
    "data_unique.drop_duplicates(inplace=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Check the resource number if unique and there are no items missing in sequence or in the run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "df = data_unique.copy()\r\n",
    "\r\n",
    "# find ResourceGroup with no ResourceName\r\n",
    "tmp = df[df['Resource'].isnull()]\r\n",
    "print(f'Warning: ResourceGroup {tmp[\"ResourceGroup\"].to_list()} need to be assigned with ResourceName')\r\n",
    "\r\n",
    "# find ResourceName with no ResourceGroup mapped\r\n",
    "tmp = df[df['ResourceGroup'].isnull()]\r\n",
    "print(f'Warning: ResourceName {tmp[\"Resource\"].to_list()} need to be mapped to ResourceGroup')\r\n",
    "\r\n",
    "# find ResourceGroup are assigned with more than one ResourceName\r\n",
    "tmp = []\r\n",
    "for key, group in df.groupby('ResourceGroup'):\r\n",
    "    if len(group)>1:\r\n",
    "        tmp.append(key)\r\n",
    "if len(tmp):\r\n",
    "    print(f'Warning: ResourceGroup {tmp} are assigned with more than one ResourceName')\r\n",
    "\r\n",
    "# find ResourceName are mapped to more than one ResourceGroup\r\n",
    "tmp = []\r\n",
    "for key, group in df.groupby('Resource'):\r\n",
    "    if len(group) > 1:\r\n",
    "        tmp.append(key)\r\n",
    "if len(tmp):\r\n",
    "    print(f'Warning: ResourceName {tmp} are mapped to more than one ResourceGroup')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: ResourceGroup ['CLOUDPOC', 'cloud', 'ellix'] need to be assigned with ResourceName\n",
      "Warning: ResourceName ['Resource-014'] need to be mapped to ResourceGroup\n",
      "Warning: ResourceName ['Resource-001', 'Resource-007', 'Resource-015'] are mapped to more than one ResourceGroup\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "# check the ResourceName sequence\r\n",
    "# Resource-001\r\n",
    "# last three digits are the sequence number\r\n",
    "df = data_unique.copy()\r\n",
    "df = df.dropna(subset=['Resource'])\r\n",
    "df['Resource'] = df['Resource'].apply(lambda x: int(x[-3:]) if isinstance(x, str) and len(x) > 3 and x[-3:].isdigit() else -1000)\r\n",
    "\r\n",
    "tmp = df[df['Resource'] == -1000]\r\n",
    "if len(tmp):\r\n",
    "    print(f'Warning: please check whether the ResourceName for ResourceGroup {tmp[\"ResourceGroup\"].to_list()} is in right format')\r\n",
    "\r\n",
    "tmp = df[df['Resource'] != -1000]\r\n",
    "tmp = df.sort_values(by='Resource', ascending=True)\r\n",
    "if tmp.loc[0]['Resource'] != 1:\r\n",
    "    print('Warning: the ResourceName sequence is not begin with 1')\r\n",
    "tmp = tmp.drop_duplicates(subset=['Resource']).reset_index()\r\n",
    "continuous_check = tmp['Resource'] - tmp['Resource'].shift()\r\n",
    "continuous_check = continuous_check[continuous_check > 1]\r\n",
    "if len(continuous_check):\r\n",
    "    print('Warning: there is no ResourceName in periods:', end=' ')\r\n",
    "    for i in continuous_check.keys():\r\n",
    "        print(f'[{tmp.loc[i-1][\"Resource\"]+1}, {tmp.loc[i][\"Resource\"]-1}]', end=' ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: there is no ResourceName in periods: [30, 33] [39, 40] "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.4 Tag Suggestions ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "data_suggest = pd.read_excel('./data/Resource Group Resource Name Tag Value Matches Azure Data Sample 20062022.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "master_values_df = pd.read_csv('./result/Tag Master Values.csv')\r\n",
    "\r\n",
    "def get_suggestion(test_resource_group, test_resource_name, master_values):\r\n",
    "    result = {}\r\n",
    "    def my_filter(char):\r\n",
    "        if char in string.ascii_letters + string.digits:\r\n",
    "            return True\r\n",
    "        return False\r\n",
    "    for i in range(len(test_resource_group)):\r\n",
    "        tmp1, tmp2 = '', ''\r\n",
    "        for m in master_values:\r\n",
    "            master_value = ''.join(filter(my_filter, m.lower()))\r\n",
    "            group = ''.join(filter(my_filter, test_resource_group[i].lower()))\r\n",
    "            name = ''.join(filter(my_filter, test_resource_name[i].lower()))\r\n",
    "            match1 = (master_value in group or group in master_value)\r\n",
    "            match2 = (master_value in name or name in master_value)\r\n",
    "            if match1 & match2:\r\n",
    "                tmp1 = tmp2 = m\r\n",
    "            elif match1:\r\n",
    "                tmp1 = m\r\n",
    "            elif match2:\r\n",
    "                tmp2 = m\r\n",
    "        result[i] = (tmp1, tmp2)\r\n",
    "    return result\r\n",
    "\r\n",
    "\r\n",
    "suggestion_dict = get_suggestion(data_suggest['ResourceGroup'].astype(str).tolist(), data_suggest['Resource Name'].astype(str).tolist(),\r\n",
    "                                 master_values_df['Tag Master Value'].astype(str).tolist())\r\n",
    "suggestion_df = pd.DataFrame.from_dict(suggestion_dict, orient='index')\r\n",
    "suggestion_df.columns = ['Tag Master Value based on ResourceGroup Match', 'Tag Master Value based on ResourceName Match']\r\n",
    "suggestion_df = pd.concat([data_suggest.loc[:, ['ResourceGroup', 'Resource Name']], suggestion_df], axis=1)\r\n",
    "suggestion_df.to_csv('./result/Suggestion.csv', index=False, header=True)\r\n",
    "suggestion_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResourceGroup</th>\n",
       "      <th>Resource Name</th>\n",
       "      <th>Tag Master Value based on ResourceGroup Match</th>\n",
       "      <th>Tag Master Value based on ResourceName Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCC</td>\n",
       "      <td>asausprodhcc</td>\n",
       "      <td>HCC</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shared-Services</td>\n",
       "      <td>storausdeploytest</td>\n",
       "      <td>Shared</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shared-Services</td>\n",
       "      <td>Tenant</td>\n",
       "      <td>Shared</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shared-services</td>\n",
       "      <td>aspausiso</td>\n",
       "      <td>Shared</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test</td>\n",
       "      <td>storwederan</td>\n",
       "      <td>pb3Test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>absa</td>\n",
       "      <td>aspweg1</td>\n",
       "      <td>Absa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>absa</td>\n",
       "      <td>waweabsacloudqa</td>\n",
       "      <td>Absa</td>\n",
       "      <td>Absa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>absa</td>\n",
       "      <td>waweinvestecadmin</td>\n",
       "      <td>Absa</td>\n",
       "      <td>Investec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>absa</td>\n",
       "      <td>waweinvestecprod</td>\n",
       "      <td>Absa</td>\n",
       "      <td>Investec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>absa</td>\n",
       "      <td>wawermbadmin</td>\n",
       "      <td>Absa</td>\n",
       "      <td>RMB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4409 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ResourceGroup      Resource Name  \\\n",
       "0                 HCC       asausprodhcc   \n",
       "1     Shared-Services  storausdeploytest   \n",
       "2     Shared-Services             Tenant   \n",
       "3     shared-services          aspausiso   \n",
       "4                Test        storwederan   \n",
       "...               ...                ...   \n",
       "4404             absa            aspweg1   \n",
       "4405             absa    waweabsacloudqa   \n",
       "4406             absa  waweinvestecadmin   \n",
       "4407             absa   waweinvestecprod   \n",
       "4408             absa       wawermbadmin   \n",
       "\n",
       "     Tag Master Value based on ResourceGroup Match  \\\n",
       "0                                              HCC   \n",
       "1                                           Shared   \n",
       "2                                           Shared   \n",
       "3                                           Shared   \n",
       "4                                          pb3Test   \n",
       "...                                            ...   \n",
       "4404                                          Absa   \n",
       "4405                                          Absa   \n",
       "4406                                          Absa   \n",
       "4407                                          Absa   \n",
       "4408                                          Absa   \n",
       "\n",
       "     Tag Master Value based on ResourceName Match  \n",
       "0                                             HCC  \n",
       "1                                                  \n",
       "2                                                  \n",
       "3                                                  \n",
       "4                                                  \n",
       "...                                           ...  \n",
       "4404                                               \n",
       "4405                                         Absa  \n",
       "4406                                     Investec  \n",
       "4407                                     Investec  \n",
       "4408                                          RMB  \n",
       "\n",
       "[4409 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "master_names = ['Client', 'Type']\r\n",
    "for master_name in master_names:\r\n",
    "    tag_values = all_tags_df[all_tags_df['Tag Name'].str.contains('|'.join(\r\n",
    "        master_names_df[master_names_df['Tag Master Name'] == master_name]['Tag Name']))]\r\n",
    "    tag_values = tag_values.groupby('Tag Value')['Tag Name'].count()\r\n",
    "    tag_values = tag_values[tag_values > 5].to_dict()\r\n",
    "    break\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "len(tag_values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('vv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5ad64190e4e8f4529ee44c4e22dd2be8cd2c7bd546daa6b217e08480c94a7a6"
   }
  },
  "interpreter": {
   "hash": "5a4c3b3f79d7b8f26d4bf85ef9493b3fe8d248934d45f78b8ebcddc328339fbe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}