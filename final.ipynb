{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datrie\r\n",
    "import string\r\n",
    "import sklearn.cluster\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import numba as nb\r\n",
    "import os\r\n",
    "import warnings\r\n",
    "\r\n",
    "from numba import njit, jit\r\n",
    "from numba.typed import Dict, List\r\n",
    "from numba import types\r\n",
    "from openpyxl import Workbook\r\n",
    "from collections import namedtuple\r\n",
    "\r\n",
    "from myLevenshtein import Levenshtein_modified\r\n",
    "\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.1 Tag Name / Value to Tag Master Name / Value Mapping ====\n",
    "\n",
    "- Load all dataset\n",
    "- Simple data pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "raw_data = []\r\n",
    "for dirpath, dirnames, filenames in os.walk('data/Azure'):\r\n",
    "    for filename in filenames:\r\n",
    "        df = pd.read_csv(dirpath + '/' + filename, low_memory=False, header=1)\r\n",
    "        df = df[['Date', 'AccountId', 'AccountName', 'DepartmentId', 'DepartmentName', 'InstanceId', 'ResourceGroup', 'Tags']]\r\n",
    "        df['ResourceName'] = df['InstanceId'].str.split('/').apply(lambda x: x[-1])\r\n",
    "        raw_data.append(df.drop(columns=['InstanceId']))\r\n",
    "raw_data = pd.concat(raw_data)\r\n",
    "data = raw_data.dropna(subset=['Tags', 'ResourceGroup']).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Parse Tags using `numba` to speed up\n",
    "- Filter Tag which has no Tag Value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "numba_dict = Dict.empty(key_type=types.int64, value_type=types.UniTuple(types.string, 2))\r\n",
    "\r\n",
    "\r\n",
    "@jit(nopython=True, nogil=True, parallel=True)\r\n",
    "def get_all_tags_typed_dict(all_tags_list, numba_dict):\r\n",
    "    index = np.int64(0)\r\n",
    "    for tags in all_tags_list:\r\n",
    "        tags = tags.replace('\"', '')\r\n",
    "        tags = tags[3:-1].split(',  ')\r\n",
    "        for tag in tags:\r\n",
    "            tmp = tag.split(': ')\r\n",
    "            if tmp[1] != '':\r\n",
    "                numba_dict[index] = (tmp[0], tmp[1])\r\n",
    "                index += 1\r\n",
    "\r\n",
    "    return numba_dict\r\n",
    "\r\n",
    "\r\n",
    "all_tags_typed_dict = get_all_tags_typed_dict(data['Tags'].tolist(), numba_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Transfer to pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "all_tags_df = pd.DataFrame.from_dict(all_tags_typed_dict, orient='index', columns=['Tag Name', 'Tag Value'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Define method to get Tag Master Names / Tag Master Values  \n",
    "*Hint:* Use `Affinity Propagation (AP)` to choose Master Names / Values automatically, this method doesn't need to identify the number of clusters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_master(words, **kwargs):\r\n",
    "    damping = kwargs.get('damping', 0.5)\r\n",
    "    max_iter = kwargs.get('max_iter', 200)\r\n",
    "    convergence_iter = kwargs.get('convergence_iter', 15)\r\n",
    "    similarity = kwargs.get('similarity', None)\r\n",
    "    affinity = 'euclidean' if similarity is None else 'precomputed'\r\n",
    "    preference = kwargs.get('preference', None)\r\n",
    "\r\n",
    "    if affinity == 'euclidean':\r\n",
    "        ap = sklearn.cluster.AffinityPropagation(affinity=affinity,\r\n",
    "                                                 damping=damping,\r\n",
    "                                                 max_iter=max_iter,\r\n",
    "                                                 convergence_iter=convergence_iter).fit(words)\r\n",
    "    else:\r\n",
    "        preference = np.median(similarity) if preference is None else preference\r\n",
    "        ap = sklearn.cluster.AffinityPropagation(affinity=affinity,\r\n",
    "                                                 damping=damping,\r\n",
    "                                                 preference=preference,\r\n",
    "                                                 max_iter=max_iter,\r\n",
    "                                                 convergence_iter=convergence_iter).fit(similarity)\r\n",
    "\r\n",
    "    master = {}\r\n",
    "    index = 0\r\n",
    "    for cluster_id in np.unique(ap.labels_):\r\n",
    "        exemplar = words[ap.cluster_centers_indices_[cluster_id]]\r\n",
    "        cluster = np.unique(words[np.nonzero(ap.labels_ == cluster_id)])\r\n",
    "        cluster_str = \", \".join(cluster)\r\n",
    "        # print(\" - *%s:* %s\" % (exemplar, cluster_str))\r\n",
    "        for point in cluster:\r\n",
    "            master[index] = {'0': point, '1': exemplar}\r\n",
    "            index += 1\r\n",
    "        #     print(Levenshtein_modified(point, exemplar), end=', ')\r\n",
    "        # print()\r\n",
    "    return master"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Get Tag Master Names\n",
    "- Store result in csv to quickly call and check them conveniently later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tag_names = all_tags_df.groupby('Tag Name')['Tag Value'].count().to_dict()\r\n",
    "words = np.asarray(list(tag_names.keys()))\r\n",
    "similarity = [[-Levenshtein_modified(w1, w2, True) for w2 in words] for w1 in words]\r\n",
    "tmp = list(tag_names.values())\r\n",
    "tmp_sum = np.sum(tmp)\r\n",
    "preference = [-(1 - i / tmp_sum)*3 for i in tmp]\r\n",
    "\r\n",
    "master_names_dict = get_master(words, similarity=similarity, preference=preference)\r\n",
    "master_names_df = pd.DataFrame.from_dict(master_names_dict, orient='index')\r\n",
    "master_names_df.columns = ['Tag Name', 'Tag Master Name']\r\n",
    "master_names_df.to_csv('./result/Tag Master Names.csv', sep=',', header=True, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Get Tag Master Values for some Tag Master Names, which can be changed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "master_names = ['Client', 'Type']\r\n",
    "master_values_df = []\r\n",
    "for master_name in master_names:\r\n",
    "    tag_values = all_tags_df[all_tags_df['Tag Name'].str.contains('|'.join(master_names_df[master_names_df['Tag Master Name'] == master_name]['Tag Name']))]\r\n",
    "    tag_values = tag_values.groupby('Tag Value')['Tag Name'].count()\r\n",
    "    tag_values = tag_values[tag_values>5].to_dict()\r\n",
    "\r\n",
    "    words = np.asarray(list(tag_values.keys()))\r\n",
    "    similarity = [[-Levenshtein_modified(w1, w2) for w2 in words] for w1 in words]\r\n",
    "    tmp = list(tag_values.values())\r\n",
    "    tmp_sum = np.sum(tmp)\r\n",
    "    preference = [-(1 - i / tmp_sum) for i in tmp]\r\n",
    "\r\n",
    "    master_values_dict = get_master(words, similarity=similarity, preference=preference)\r\n",
    "    tmp = pd.DataFrame.from_dict(master_values_dict, orient='index')\r\n",
    "    tmp.columns = ['Tag Value', 'Tag Master Value']\r\n",
    "    tmp['Tag Master Name'] = [master_name] * len(tmp)\r\n",
    "    master_values_df.append(tmp)\r\n",
    "\r\n",
    "master_values_df = pd.concat(master_values_df, ignore_index=True)\r\n",
    "master_values_df.to_csv('./result/Tag Master Values.csv', sep=',', header=True, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Match Tag Name to Tag Master Name & give matching percentage\n",
    "- Store Tag Master Value in Trie to quickly find whether one string exsits, whose time complexity is *O(n)*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "trie1 = datrie.Trie(string.ascii_letters + string.digits)\r\n",
    "master_names_df = pd.read_csv('./result/Tag Master Names.csv', low_memory=False)\r\n",
    "master_names = master_names_df['Tag Master Name'].unique()\r\n",
    "for i in range(len(master_names)):\r\n",
    "    trie1[''.join(filter(str.isalnum, str(master_names[i]).lower()))] = i\r\n",
    "trie1.save('./result/Tag Master Name Trie.txt')\r\n",
    "\r\n",
    "trie2 = datrie.Trie(string.ascii_letters + string.digits)\r\n",
    "master_values_df = pd.read_csv('./result/Tag Master Values.csv', low_memory=False)\r\n",
    "master_values = master_values_df['Tag Master Value'].unique()\r\n",
    "for i in range(len(master_values)):\r\n",
    "    trie2[''.join(filter(str.isalnum, str(master_values[i]).lower()))] = i\r\n",
    "trie2.save('./result/Tag Master Value Trie.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "trie = datrie.Trie.load('./result/Tag Master Name Trie.txt')\r\n",
    "tag = 'DatabrickInstace'\r\n",
    "tag = ''.join(filter(str.isalnum, tag.lower()))\r\n",
    "test_list = [tag[i:i + 4] for i in range(len(tag))]\r\n",
    "\r\n",
    "suggestion = []\r\n",
    "for t in test_list:\r\n",
    "    res = trie.items(t)\r\n",
    "    for r in res:\r\n",
    "        master = master_names[r[1]]\r\n",
    "        distance = Levenshtein_modified(tag, master)\r\n",
    "        percentage = (1 - distance / max(len(master), len(tag))) * 100\r\n",
    "        if distance != 1000:\r\n",
    "            suggestion.append([master, distance, f'{percentage:.2f}%'])\r\n",
    "suggestion = np.array(suggestion)\r\n",
    "suggestion = suggestion[np.argsort(suggestion[:, 2])][::-1]\r\n",
    "suggestion"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['databricks-instance-name', '6.0', '75.00%'],\n",
       "       ['DatabricksInstancePoolId', '8.0', '66.67%'],\n",
       "       ['DatabricksInstanceGroupId', '9.0', '64.00%'],\n",
       "       ['Databricks-ElasticDisk', '9.0', '59.09%']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "trie = datrie.Trie.load('./result/Tag Master Value Trie.txt')\r\n",
    "tag = 'waweabsacfadmin'\r\n",
    "tag = ''.join(filter(str.isalnum, tag.lower()))\r\n",
    "test_list = [tag[i:i + 4] for i in range(len(tag))]\r\n",
    "\r\n",
    "suggestion = []\r\n",
    "for t in test_list:\r\n",
    "    res = trie.items(t)\r\n",
    "    for r in res:\r\n",
    "        master = master_values[r[1]]\r\n",
    "        distance = Levenshtein_modified(tag, master)\r\n",
    "        percentage = (1 - distance / max(len(master), len(tag))) * 100\r\n",
    "        if distance != 1000:\r\n",
    "            suggestion.append([master, distance, f'{percentage:.2f}%'])\r\n",
    "suggestion = np.array(suggestion)\r\n",
    "suggestion = suggestion[np.argsort(suggestion[:, 2])][::-1]\r\n",
    "suggestion"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['ABSACF', '9.0', '40.00%'],\n",
       "       ['Absa', '11.0', '26.67%']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.2 MO Code & CC Code Matching ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Load dataset\n",
    "- Parse \"cloud_tags\" to extract \"resourcetags_user_costcenter\" & \"resourcetags_user_appid\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# AWS raw data is too large and we only need the column of 'cloud_tags'\r\n",
    "data_aws = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='Tags Extracted')\r\n",
    "data_aws = data_aws.dropna().reset_index()\r\n",
    "\r\n",
    "data_aws_mo = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='measured object hierarchy - 202')\r\n",
    "data_aws_mo = data_aws_mo.dropna(subset=['MeasuredObjectCode']).reset_index()\r\n",
    "\r\n",
    "data_aws_cc = pd.read_excel('./data/Sample Data for AWS Private and Confidential.xlsx', sheet_name='cost centre hierarchy - 2022062')\r\n",
    "data_aws_cc = data_aws_cc.dropna(subset=['CostCentreCode']).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@jit(nopython=True, nogil=True, parallel=True)\r\n",
    "def get_costcenter_appid(all_tags_list):\r\n",
    "    index = np.int64(0)\r\n",
    "    costercenter, appid = [], []\r\n",
    "    for tags in all_tags_list:\r\n",
    "        tags = (tags.replace('\"', '')).replace('\\\\', '')\r\n",
    "        tags = tags[1:-1].split(', ')\r\n",
    "        for tag in tags:\r\n",
    "            tmp = tag.split(' : ')\r\n",
    "            if tmp[0] == 'resourcetags_user_costcenter':\r\n",
    "                costercenter.append(tmp[1])\r\n",
    "            if tmp[0] == 'resourcetags_user_appid':\r\n",
    "                appid.append(tmp[1])\r\n",
    "\r\n",
    "    return costercenter, appid\r\n",
    "\r\n",
    "costercenter, appid = get_costcenter_appid(data_aws['cloud_tags'].to_list())\r\n",
    "costercenter, appid = np.unique(costercenter), np.unique(appid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Store Measured Object Code & Cost Centre Code in Trie"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mo = data_aws_mo['MeasuredObjectCode'].astype(str).unique()\r\n",
    "cc = data_aws_cc['CostCentreCode'].astype(str).unique()\r\n",
    "\r\n",
    "# 10: MeasuredObjectCode\r\n",
    "# 01: CostCentreCode\r\n",
    "# 11: is both MeasuredObjectCode and CostCentreCode\r\n",
    "trie = datrie.Trie(string.ascii_letters + string.digits + ' -_')\r\n",
    "for m in mo:\r\n",
    "    trie[m] = 10\r\n",
    "for c in cc:\r\n",
    "    trie[c] = 11 if c in trie else 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Check each 'resourcetags_user_costcenter' & 'resourcetags_user_appid' value\n",
    "- Store results in xlsx"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def mo_cc_match(test_values, test_name, writer, sheet_name):\r\n",
    "    res = {}\r\n",
    "    index = 0\r\n",
    "    for c in test_values:\r\n",
    "        tmp = trie[str(c)] if str(c) in trie else 0\r\n",
    "        match1 = c if tmp // 10 else 'No'\r\n",
    "        match2 = c if tmp % 10 else 'No'\r\n",
    "        res[index] = (c, match1, match2)\r\n",
    "        index += 1\r\n",
    "    res = pd.DataFrame(res).T\r\n",
    "    res.columns = [test_name, 'MO Code Match', 'CC Code Match']\r\n",
    "    res.to_excel(writer, sheet_name=sheet_name, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_name = './result/MO_CC Code Match.xlsx'\r\n",
    "if not os.path.exists(file_name):\r\n",
    "    Workbook().save(file_name)\r\n",
    "writer = pd.ExcelWriter(file_name, engine='openpyxl', mode='w')\r\n",
    "mo_cc_match(costercenter, 'resourcetags_user_costcenter', writer, 'user_costcenter')\r\n",
    "mo_cc_match(appid, 'resourcetags_user_appid', writer, 'user_appid')\r\n",
    "writer.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ==== 3.3 Unique Tag Value Check ===="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('vv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5ad64190e4e8f4529ee44c4e22dd2be8cd2c7bd546daa6b217e08480c94a7a6"
   }
  },
  "interpreter": {
   "hash": "5a4c3b3f79d7b8f26d4bf85ef9493b3fe8d248934d45f78b8ebcddc328339fbe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}